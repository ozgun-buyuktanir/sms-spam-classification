{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.cli import download\n",
    "from spacy import load\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files('uciml/sms-spam-collection-dataset', path='./', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/querriqe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to\n",
      "[nltk_data]     /home/querriqe/nltk_data...\n",
      "[nltk_data]   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/querriqe/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 117.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/querriqe/.local/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.25.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: jinja2 in /home/querriqe/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/querriqe/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.5.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/querriqe/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/querriqe/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/querriqe/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/querriqe/.local/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet2022')\n",
    "nltk.download('omw-1.4')\n",
    "download('en_core_web_sm')\n",
    "nlp = load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "...   ..                                                ...\n",
       "5567   1  This is the 2nd time we have tried 2 contact u...\n",
       "5568   0              Will Ì_ b going to esplanade fr home?\n",
       "5569   0  Pity, * was in mood for that. So...any other s...\n",
       "5570   0  The guy did some bitching but I acted like i'd...\n",
       "5571   0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "df['v1'] = le.fit_transform(df['v1'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer() #lemmatizer (cats -> cat, dogs -> dog, etc.)\n",
    "stop_words = stopwords.words('english') #stopwords (is, at, etc.)\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+') \n",
    "\n",
    "def token_list(massage):\n",
    "    tokens = tokenizer.tokenize(massage)\n",
    "    lc_tokens = [t.lower() for t in tokens] # lowercased tokens\n",
    "    lm_tokens = [lemmatizer.lemmatize(t) for t in lc_tokens] #lemmatized tokens\n",
    "    tokens = [t for t in lm_tokens if t not in stop_words] #get rid of stopwords(is, at, etc.)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    3867\n",
       "1     590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "train_test_rat = int(len(df) * 0.8)\n",
    "train_df, test_df = df[:train_test_rat], df[train_test_rat:]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter = {}\n",
    "\n",
    "for message in train_df['v2']:\n",
    "    tokenlist = token_list(message)\n",
    "    \n",
    "    for token in tokenlist:\n",
    "        if token in token_counter:\n",
    "            token_counter[token] +=1\n",
    "        else:\n",
    "            token_counter[token] = 1\n",
    "\n",
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_token(token,threshold):\n",
    "    if token not in token_counter:\n",
    "        return False\n",
    "    else:\n",
    "        return token_counter[token] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set()\n",
    "\n",
    "for token in token_counter:\n",
    "    if keep_token(token,100):\n",
    "        features.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "token_map = {t:i for t,i in zip(features, range(len(features)))}\n",
    "print(len(token_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_count_vector(message):\n",
    "    count_vector = np.zeros(len(features))\n",
    "\n",
    "    processed_list_of_tokens = token_list(message)\n",
    "\n",
    "    for token in processed_list_of_tokens:\n",
    "        if token not in features:\n",
    "            continue\n",
    "        index = token_map[token]\n",
    "        count_vector[index] += 1\n",
    "        \n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_X_y(dff):\n",
    "    y = dff['v1'].to_numpy().astype(int)\n",
    "    \n",
    "    mess_col = dff['v2']\n",
    "    count_vectors = []\n",
    "    \n",
    "    for message in mess_col:\n",
    "        count_vector = message_to_count_vector(message)\n",
    "        count_vectors.append(count_vector)\n",
    "        \n",
    "    X= np.array(count_vectors).astype(int)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = to_X_y(train_df)\n",
    "\n",
    "X_test, y_test = to_X_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>cross-val accuracy score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>0.099950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.948948</td>\n",
       "      <td>0.162918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>0.012634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.953436</td>\n",
       "      <td>0.224706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.952595</td>\n",
       "      <td>0.195025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.954278</td>\n",
       "      <td>0.027442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model name  cross-val accuracy score      time\n",
       "0           Logistic Regression                  0.940533  0.099950\n",
       "1                           SVC                  0.948948  0.162918\n",
       "2        K-Neighbors Classifier                  0.930715  0.000842\n",
       "3      Decision Tree Classifier                  0.941094  0.012634\n",
       "4      Random Forest Classifier                  0.953436  0.224706\n",
       "5  Gradient Boosting Classifier                  0.952595  0.195025\n",
       "6                XGB Classifier                  0.954278  0.027442"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "init_models = { 'Logistic Regression' :  LogisticRegression(),\n",
    "                'SVC': SVC(),\n",
    "                'K-Neighbors Classifier': KNeighborsClassifier(),\n",
    "                'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "                'Random Forest Classifier' : RandomForestClassifier(),\n",
    "                'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "                'XGB Classifier' : XGBClassifier(),\n",
    "               }\n",
    "\n",
    "timer=[]\n",
    "acc = []\n",
    "models_names = []\n",
    "for i, (key,model) in enumerate(init_models.items()):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    models_names.append(key)\n",
    "    acc.append(np.mean(cross_val_score(model, X_train, y_train, cv=5)))\n",
    "    timer.append(end_time-start_time)\n",
    "models_scores = pd.DataFrame({'model name': models_names, 'cross-val accuracy score': acc, 'time': timer})\n",
    "models_scores.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ........................leaf_size=20, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=3; total time=   0.0s[CV] END ........................leaf_size=20, n_neighbors=3; total time=   0.0s\n",
      "\n",
      "[CV] END ........................leaf_size=20, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.0s[CV] END ........................leaf_size=30, n_neighbors=6; total time=   0.0s\n",
      "\n",
      "[CV] END ........................leaf_size=40, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=4; total time=   0.0s[CV] END ........................leaf_size=50, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=5; total time=   0.0s\n",
      "\n",
      "[CV] END ........................leaf_size=50, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=5; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=20, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=30, n_neighbors=6; total time=   0.0s\n",
      "[CV] END ........................leaf_size=40, n_neighbors=4; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=3; total time=   0.0s\n",
      "[CV] END ........................leaf_size=50, n_neighbors=3; total time=   0.0s\n",
      "{'leaf_size': 20, 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = [3,4,5,6]\n",
    "leaf_size = [20,30,40,50]\n",
    "params = { 'n_neighbors': n_neighbors, 'leaf_size': leaf_size }\n",
    "\n",
    "boost_grid = GridSearchCV(estimator = model, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='accuracy',n_jobs = -1)\n",
    "boost_grid.fit(X_train,y_train)\n",
    "print(boost_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       775\n",
      "           1       0.92      0.67      0.77       117\n",
      "\n",
      "    accuracy                           0.95       892\n",
      "   macro avg       0.93      0.83      0.87       892\n",
      "weighted avg       0.95      0.95      0.94       892\n",
      " \n",
      "\n",
      "time:  0.14032626152038574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3, leaf_size=20)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_val)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(classification_report(y_val, prediction), '\\n')\n",
    "print('time: ', end_time-start_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you. I like you as well...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Tones This week include: 1)McFly-All Ab..,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am not sure about night menu. . . I know onl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hope ur head doesn't hurt 2 much ! Am ploughin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hey what how about your project. Started aha da.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>I came hostel. I m going to sleep. Plz call me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>Prabha..i'm soryda..realy..frm heart i'm sory</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Nt joking seriously i told</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>In work now. Going have in few min.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  actual  prediction\n",
       "0                      Thank you. I like you as well...       0           0\n",
       "1     New Tones This week include: 1)McFly-All Ab..,...       1           0\n",
       "2     I am not sure about night menu. . . I know onl...       0           0\n",
       "3     Hope ur head doesn't hurt 2 much ! Am ploughin...       0           0\n",
       "4      Hey what how about your project. Started aha da.       0           0\n",
       "...                                                 ...     ...         ...\n",
       "1110  I came hostel. I m going to sleep. Plz call me...       0           0\n",
       "1111                             Sorry, I'll call later       0           0\n",
       "1112      Prabha..i'm soryda..realy..frm heart i'm sory       0           0\n",
       "1113                         Nt joking seriously i told       0           0\n",
       "1114                In work now. Going have in few min.       0           0\n",
       "\n",
       "[1115 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_test_df = pd.DataFrame({'message': test_df['v2'], 'actual': y_test, 'prediction': model.predict(X_test)})\n",
    "KNN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.2s\n",
      "[CV] END ....................max_depth=None, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...................max_depth=None, n_estimators=100; total time=   0.4s\n",
      "[CV] END .......................max_depth=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=200; total time=   0.7s\n",
      "[CV] END ...................max_depth=None, n_estimators=200; total time=   0.7s\n",
      "[CV] END ...................max_depth=None, n_estimators=200; total time=   0.8s\n",
      "[CV] END .......................max_depth=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=200; total time=   0.8s\n",
      "[CV] END .......................max_depth=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=200; total time=   0.8s\n",
      "[CV] END ......................max_depth=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......................max_depth=1, n_estimators=500; total time=   0.8s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......................max_depth=1, n_estimators=500; total time=   0.8s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................max_depth=None, n_estimators=500; total time=   1.8s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......................max_depth=1, n_estimators=500; total time=   0.8s\n",
      "[CV] END ...................max_depth=None, n_estimators=500; total time=   1.8s\n",
      "[CV] END ...................max_depth=None, n_estimators=500; total time=   1.8s\n",
      "[CV] END ...................max_depth=None, n_estimators=500; total time=   1.8s\n",
      "[CV] END ...................max_depth=None, n_estimators=500; total time=   1.8s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=1, n_estimators=500; total time=   0.7s\n",
      "[CV] END ......................max_depth=1, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......................max_depth=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .....................max_depth=1, n_estimators=1000; total time=   1.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END .....................max_depth=1, n_estimators=1000; total time=   1.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END .....................max_depth=1, n_estimators=1000; total time=   1.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=3, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..................max_depth=None, n_estimators=1000; total time=   3.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV] END ......................max_depth=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=3, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..................max_depth=None, n_estimators=1000; total time=   3.6s\n",
      "[CV] END ..................max_depth=None, n_estimators=1000; total time=   3.6s\n",
      "[CV] END .....................max_depth=2, n_estimators=1000; total time=   1.7s\n",
      "[CV] END ..................max_depth=None, n_estimators=1000; total time=   3.6s\n",
      "[CV] END .....................max_depth=2, n_estimators=1000; total time=   1.6s\n",
      "[CV] END .....................max_depth=2, n_estimators=1000; total time=   1.6s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..................max_depth=None, n_estimators=1000; total time=   3.9s\n",
      "[CV] END ......................max_depth=3, n_estimators=500; total time=   0.8s\n",
      "[CV] END ......................max_depth=3, n_estimators=500; total time=   0.7s\n",
      "[CV] END ......................max_depth=3, n_estimators=500; total time=   0.8s\n",
      "[CV] END .....................max_depth=1, n_estimators=1000; total time=   1.5s\n",
      "[CV] END .....................max_depth=1, n_estimators=1000; total time=   1.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=500; total time=   0.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=500; total time=   0.6s\n",
      "[CV] END .....................max_depth=3, n_estimators=1000; total time=   1.3s\n",
      "[CV] END .....................max_depth=3, n_estimators=1000; total time=   1.4s\n",
      "[CV] END .....................max_depth=3, n_estimators=1000; total time=   1.3s\n",
      "[CV] END .....................max_depth=2, n_estimators=1000; total time=   1.2s\n",
      "[CV] END .....................max_depth=2, n_estimators=1000; total time=   1.2s\n",
      "[CV] END .....................max_depth=3, n_estimators=1000; total time=   1.3s\n",
      "[CV] END .....................max_depth=3, n_estimators=1000; total time=   1.1s\n",
      "{'max_depth': None, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "n_estimators = [50,100,200,500,1000]\n",
    "max_depth = [None,1,2,3]\n",
    "params = { 'n_estimators': n_estimators, 'max_depth': max_depth }\n",
    "\n",
    "boost_grid = GridSearchCV(estimator = model, param_grid = params, \n",
    "                                cv = 5, verbose=2, scoring='accuracy',n_jobs = -1)\n",
    "boost_grid.fit(X_train,y_train)\n",
    "print(boost_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       775\n",
      "           1       0.85      0.82      0.83       117\n",
      "\n",
      "    accuracy                           0.96       892\n",
      "   macro avg       0.91      0.90      0.91       892\n",
      "weighted avg       0.96      0.96      0.96       892\n",
      " \n",
      "\n",
      "time:  0.4513063430786133\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(classification_report(y_val, prediction), '\\n')\n",
    "print('time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_test_df = pd.DataFrame({'message': test_df['v2'], 'actual': y_test, 'prediction': model.predict(X_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                message  actual  prediction\n",
      "1     New Tones This week include: 1)McFly-All Ab..,...       1           0\n",
      "10    PRIVATE! Your 2003 Account Statement for <fone...       1           0\n",
      "16              Call me da, i am waiting for your call.       0           1\n",
      "25    SMSSERVICES. for yourinclusive text credits, p...       1           0\n",
      "27    BangBabes Ur order is on the way. U SHOULD rec...       1           0\n",
      "...                                                 ...     ...         ...\n",
      "966   Get your garden ready for summer with a FREE s...       1           0\n",
      "999   How come it takes so little time for a child w...       1           0\n",
      "1048  Bloomberg -Message center +447797706009 Why wa...       1           0\n",
      "1056  You will be receiving this week's Triple Echo ...       1           0\n",
      "1067  Fantasy Football is back on your TV. Go to Sky...       1           0\n",
      "\n",
      "[65 rows x 3 columns]\n",
      "0.9417040358744395\n"
     ]
    }
   ],
   "source": [
    "print(KNN_test_df.loc[KNN_test_df['actual'] != KNN_test_df['prediction']])\n",
    "print(1 - (len(KNN_test_df.loc[KNN_test_df['actual'] != KNN_test_df['prediction']])/len(KNN_test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                message  actual  prediction\n",
      "1     New Tones This week include: 1)McFly-All Ab..,...       1           0\n",
      "21                       I'm in a movie. Call me 4 wat?       0           1\n",
      "35             RCT' THNQ Adrian for U text. Rgds Vatian       1           0\n",
      "56    You are now unsubscribed all services. Get ton...       1           0\n",
      "66    Please CALL 08712402972 immediately as there i...       1           0\n",
      "69    Bored housewives! Chat n date now! 0871750.77....       1           0\n",
      "77    I take it the post has come then! You must hav...       0           1\n",
      "88    You won't believe it but it's true. It's Incre...       1           0\n",
      "104   Hello darlin ive finished college now so txt m...       0           1\n",
      "115   LIFE has never been this much fun and great un...       1           0\n",
      "117   Adult 18 Content Your video will be with you s...       1           0\n",
      "138   Want explicit SEX in 30 secs? Ring 02073162414...       1           0\n",
      "145   U were outbid by simonwatson5120 on the Shinco...       1           0\n",
      "150   HOT LIVE FANTASIES call now 08707500020 Just 2...       1           0\n",
      "158   YES! The only place in town to meet exciting a...       1           0\n",
      "191   Wot u up 2? Thout u were gonna call me!! Txt b...       0           1\n",
      "245   Monthly password for wap. mobsi.com is 391784....       1           0\n",
      "278      Am only searching for good dual sim mobile pa.       0           1\n",
      "279   We have new local dates in your area - Lots of...       1           0\n",
      "294   I love u 2 babe! R u sure everything is alrite...       0           1\n",
      "305   Forgot you were working today! Wanna chat, but...       0           1\n",
      "321   You won't believe it but it's true. It's Incre...       1           0\n",
      "328   JADE ITS PAUL. Y DIDNåÕT U TXT ME? DO U REMEMB...       0           1\n",
      "366          SMS. ac sun0819 posts HELLO:\\You seem cool       1           0\n",
      "452   My mobile number.pls sms ur mail id.convey reg...       0           1\n",
      "547   Hey gorgeous man. My work mobile number is. Ha...       0           1\n",
      "549   Can you call me plz. Your number shows out of ...       0           1\n",
      "585                      Customer place i will call you       0           1\n",
      "599   HOT LIVE FANTASIES call now 08707509020 Just 2...       1           0\n",
      "633   Hi Dear Call me its urgnt. I don't know whats ...       0           1\n",
      "658   Rock yr chik. Get 100's of filthy films &XXX p...       1           0\n",
      "666   Dear,regret i cudnt pick call.drove down frm c...       0           1\n",
      "667   Gr8 Poly tones 4 ALL mobs direct 2u rply with ...       1           0\n",
      "673   Sexy Singles are waiting for you! Text your AG...       1           0\n",
      "721   Cashbin.co.uk (Get lots of cash this weekend!)...       1           0\n",
      "727   In The Simpsons Movie released in July 2007 na...       1           0\n",
      "792   Are you unique enough? Find out from 30th Augu...       1           0\n",
      "797   XCLUSIVE@CLUBSAISAI 2MOROW 28/5 SOIREE SPECIAL...       1           0\n",
      "800   Welcome! Please reply with your AGE and GENDER...       1           0\n",
      "818   Would really appreciate if you call me. Just n...       0           1\n",
      "827           Filthy stories and GIRLS waiting for your       1           0\n",
      "832   dating:i have had two of these. Only started a...       1           0\n",
      "839   Latest News! Police station toilet stolen, cop...       1           0\n",
      "841   TBS/PERSOLVO. been chasing us since Sept forå£...       1           0\n",
      "845   YOUR CHANCE TO BE ON A REALITY FANTASY SHOW ca...       1           0\n",
      "852   This message is brought to you by GMW Ltd. and...       1           0\n",
      "869   .Please charge my mobile when you get up in mo...       0           1\n",
      "919   Hi, this is Mandy Sullivan calling from HOTMIX...       1           0\n",
      "922      Aight, text me tonight and we'll see what's up       0           1\n",
      "999   How come it takes so little time for a child w...       1           0\n",
      "1048  Bloomberg -Message center +447797706009 Why wa...       1           0\n",
      "1049  Guess what! Somebody you know secretly fancies...       1           0\n",
      "1056  You will be receiving this week's Triple Echo ...       1           0\n",
      "1061  Yetunde, i'm sorry but moji and i seem too bus...       0           1\n",
      "1110  I came hostel. I m going to sleep. Plz call me...       0           1\n",
      "0.9506726457399103\n"
     ]
    }
   ],
   "source": [
    "print(RFC_test_df.loc[RFC_test_df['actual'] != RFC_test_df['prediction']])\n",
    "print(1 - (len(RFC_test_df.loc[RFC_test_df['actual'] != RFC_test_df['prediction']])/len(RFC_test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "I chosed fastest and most accurate models. \n",
    "- KNN: %94,17 accuracy within 0.141373872756958 seconds\n",
    "- RFC: %95,06 accuracy within 0.4513063430786133 seconds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
